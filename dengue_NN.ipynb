{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Flatten\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('dengue_features_train.csv')\n",
    "target = pd.read_csv('dengue_labels_train.csv')\n",
    "df = pd.merge(features, target, on=['city','year','weekofyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                                       0\n",
       "year                                       0\n",
       "weekofyear                                 0\n",
       "week_start_date                            0\n",
       "ndvi_ne                                  194\n",
       "ndvi_nw                                   52\n",
       "ndvi_se                                   22\n",
       "ndvi_sw                                   22\n",
       "precipitation_amt_mm                      13\n",
       "reanalysis_air_temp_k                     10\n",
       "reanalysis_avg_temp_k                     10\n",
       "reanalysis_dew_point_temp_k               10\n",
       "reanalysis_max_air_temp_k                 10\n",
       "reanalysis_min_air_temp_k                 10\n",
       "reanalysis_precip_amt_kg_per_m2           10\n",
       "reanalysis_relative_humidity_percent      10\n",
       "reanalysis_sat_precip_amt_mm              13\n",
       "reanalysis_specific_humidity_g_per_kg     10\n",
       "reanalysis_tdtr_k                         10\n",
       "station_avg_temp_c                        43\n",
       "station_diur_temp_rng_c                   43\n",
       "station_max_temp_c                        20\n",
       "station_min_temp_c                        14\n",
       "station_precip_mm                         22\n",
       "total_cases                                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) - len(df[df['city'] == 'iq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I will check sj and iq boardline first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>2008-03-18</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.101629</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297.404286</td>\n",
       "      <td>297.435714</td>\n",
       "      <td>292.205714</td>\n",
       "      <td>299.8</td>\n",
       "      <td>294.9</td>\n",
       "      <td>0.90</td>\n",
       "      <td>72.915714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.737143</td>\n",
       "      <td>3.871429</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>7.042857</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>13</td>\n",
       "      <td>2008-03-25</td>\n",
       "      <td>0.077850</td>\n",
       "      <td>-0.039900</td>\n",
       "      <td>0.310471</td>\n",
       "      <td>0.296243</td>\n",
       "      <td>27.19</td>\n",
       "      <td>296.958571</td>\n",
       "      <td>296.957143</td>\n",
       "      <td>292.095714</td>\n",
       "      <td>299.7</td>\n",
       "      <td>294.4</td>\n",
       "      <td>7.55</td>\n",
       "      <td>74.247143</td>\n",
       "      <td>27.19</td>\n",
       "      <td>13.644286</td>\n",
       "      <td>2.885714</td>\n",
       "      <td>25.042857</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>14</td>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>-0.038000</td>\n",
       "      <td>-0.016833</td>\n",
       "      <td>0.119371</td>\n",
       "      <td>0.066386</td>\n",
       "      <td>3.82</td>\n",
       "      <td>298.081429</td>\n",
       "      <td>298.228571</td>\n",
       "      <td>293.235714</td>\n",
       "      <td>299.8</td>\n",
       "      <td>296.5</td>\n",
       "      <td>3.67</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>3.82</td>\n",
       "      <td>14.662857</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>26.242857</td>\n",
       "      <td>6.814286</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>15</td>\n",
       "      <td>2008-04-08</td>\n",
       "      <td>-0.155200</td>\n",
       "      <td>-0.052750</td>\n",
       "      <td>0.137757</td>\n",
       "      <td>0.141214</td>\n",
       "      <td>16.96</td>\n",
       "      <td>297.460000</td>\n",
       "      <td>297.564286</td>\n",
       "      <td>292.732857</td>\n",
       "      <td>299.4</td>\n",
       "      <td>295.8</td>\n",
       "      <td>35.00</td>\n",
       "      <td>75.027143</td>\n",
       "      <td>16.96</td>\n",
       "      <td>14.184286</td>\n",
       "      <td>2.185714</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>29.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>16</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.209843</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297.630000</td>\n",
       "      <td>297.778571</td>\n",
       "      <td>292.274286</td>\n",
       "      <td>299.7</td>\n",
       "      <td>295.9</td>\n",
       "      <td>4.82</td>\n",
       "      <td>72.285714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.858571</td>\n",
       "      <td>2.785714</td>\n",
       "      <td>25.314286</td>\n",
       "      <td>6.242857</td>\n",
       "      <td>29.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>17</td>\n",
       "      <td>2008-04-22</td>\n",
       "      <td>-0.037000</td>\n",
       "      <td>-0.010367</td>\n",
       "      <td>0.077314</td>\n",
       "      <td>0.090586</td>\n",
       "      <td>0.00</td>\n",
       "      <td>298.672857</td>\n",
       "      <td>298.692857</td>\n",
       "      <td>294.280000</td>\n",
       "      <td>300.9</td>\n",
       "      <td>295.9</td>\n",
       "      <td>2.17</td>\n",
       "      <td>76.960000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.671429</td>\n",
       "      <td>3.957143</td>\n",
       "      <td>27.042857</td>\n",
       "      <td>7.514286</td>\n",
       "      <td>31.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>26</td>\n",
       "      <td>2000-07-01</td>\n",
       "      <td>0.192886</td>\n",
       "      <td>0.132257</td>\n",
       "      <td>0.340886</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>25.41</td>\n",
       "      <td>296.740000</td>\n",
       "      <td>298.450000</td>\n",
       "      <td>295.184286</td>\n",
       "      <td>307.3</td>\n",
       "      <td>293.1</td>\n",
       "      <td>43.19</td>\n",
       "      <td>92.418571</td>\n",
       "      <td>25.41</td>\n",
       "      <td>16.651429</td>\n",
       "      <td>8.928571</td>\n",
       "      <td>26.400000</td>\n",
       "      <td>10.775000</td>\n",
       "      <td>32.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>27</td>\n",
       "      <td>2000-07-08</td>\n",
       "      <td>0.216833</td>\n",
       "      <td>0.276100</td>\n",
       "      <td>0.289457</td>\n",
       "      <td>0.241657</td>\n",
       "      <td>60.61</td>\n",
       "      <td>296.634286</td>\n",
       "      <td>298.428571</td>\n",
       "      <td>295.358571</td>\n",
       "      <td>306.6</td>\n",
       "      <td>291.1</td>\n",
       "      <td>46.00</td>\n",
       "      <td>93.581429</td>\n",
       "      <td>60.61</td>\n",
       "      <td>16.862857</td>\n",
       "      <td>10.314286</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>11.566667</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>28</td>\n",
       "      <td>2000-07-15</td>\n",
       "      <td>0.176757</td>\n",
       "      <td>0.173129</td>\n",
       "      <td>0.204114</td>\n",
       "      <td>0.128014</td>\n",
       "      <td>55.52</td>\n",
       "      <td>296.415714</td>\n",
       "      <td>297.392857</td>\n",
       "      <td>295.622857</td>\n",
       "      <td>304.5</td>\n",
       "      <td>292.6</td>\n",
       "      <td>64.77</td>\n",
       "      <td>95.848571</td>\n",
       "      <td>55.52</td>\n",
       "      <td>17.120000</td>\n",
       "      <td>7.385714</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>iq</td>\n",
       "      <td>2000</td>\n",
       "      <td>29</td>\n",
       "      <td>2000-07-22</td>\n",
       "      <td>0.227729</td>\n",
       "      <td>0.145429</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.200314</td>\n",
       "      <td>5.60</td>\n",
       "      <td>295.357143</td>\n",
       "      <td>296.228571</td>\n",
       "      <td>292.797143</td>\n",
       "      <td>303.6</td>\n",
       "      <td>288.6</td>\n",
       "      <td>23.96</td>\n",
       "      <td>87.234286</td>\n",
       "      <td>5.60</td>\n",
       "      <td>14.431429</td>\n",
       "      <td>9.114286</td>\n",
       "      <td>25.766667</td>\n",
       "      <td>10.533333</td>\n",
       "      <td>31.5</td>\n",
       "      <td>14.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city  year  weekofyear week_start_date   ndvi_ne   ndvi_nw   ndvi_se  \\\n",
       "930   sj  2008          12      2008-03-18  0.044900  0.024450  0.101629   \n",
       "931   sj  2008          13      2008-03-25  0.077850 -0.039900  0.310471   \n",
       "932   sj  2008          14      2008-04-01 -0.038000 -0.016833  0.119371   \n",
       "933   sj  2008          15      2008-04-08 -0.155200 -0.052750  0.137757   \n",
       "934   sj  2008          16      2008-04-15  0.001800       NaN  0.203900   \n",
       "935   sj  2008          17      2008-04-22 -0.037000 -0.010367  0.077314   \n",
       "936   iq  2000          26      2000-07-01  0.192886  0.132257  0.340886   \n",
       "937   iq  2000          27      2000-07-08  0.216833  0.276100  0.289457   \n",
       "938   iq  2000          28      2000-07-15  0.176757  0.173129  0.204114   \n",
       "939   iq  2000          29      2000-07-22  0.227729  0.145429  0.254200   \n",
       "\n",
       "      ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  \\\n",
       "930  0.088000                  0.00             297.404286   \n",
       "931  0.296243                 27.19             296.958571   \n",
       "932  0.066386                  3.82             298.081429   \n",
       "933  0.141214                 16.96             297.460000   \n",
       "934  0.209843                  0.00             297.630000   \n",
       "935  0.090586                  0.00             298.672857   \n",
       "936  0.247200                 25.41             296.740000   \n",
       "937  0.241657                 60.61             296.634286   \n",
       "938  0.128014                 55.52             296.415714   \n",
       "939  0.200314                  5.60             295.357143   \n",
       "\n",
       "     reanalysis_avg_temp_k  reanalysis_dew_point_temp_k  \\\n",
       "930             297.435714                   292.205714   \n",
       "931             296.957143                   292.095714   \n",
       "932             298.228571                   293.235714   \n",
       "933             297.564286                   292.732857   \n",
       "934             297.778571                   292.274286   \n",
       "935             298.692857                   294.280000   \n",
       "936             298.450000                   295.184286   \n",
       "937             298.428571                   295.358571   \n",
       "938             297.392857                   295.622857   \n",
       "939             296.228571                   292.797143   \n",
       "\n",
       "     reanalysis_max_air_temp_k  reanalysis_min_air_temp_k  \\\n",
       "930                      299.8                      294.9   \n",
       "931                      299.7                      294.4   \n",
       "932                      299.8                      296.5   \n",
       "933                      299.4                      295.8   \n",
       "934                      299.7                      295.9   \n",
       "935                      300.9                      295.9   \n",
       "936                      307.3                      293.1   \n",
       "937                      306.6                      291.1   \n",
       "938                      304.5                      292.6   \n",
       "939                      303.6                      288.6   \n",
       "\n",
       "     reanalysis_precip_amt_kg_per_m2  reanalysis_relative_humidity_percent  \\\n",
       "930                             0.90                             72.915714   \n",
       "931                             7.55                             74.247143   \n",
       "932                             3.67                             74.600000   \n",
       "933                            35.00                             75.027143   \n",
       "934                             4.82                             72.285714   \n",
       "935                             2.17                             76.960000   \n",
       "936                            43.19                             92.418571   \n",
       "937                            46.00                             93.581429   \n",
       "938                            64.77                             95.848571   \n",
       "939                            23.96                             87.234286   \n",
       "\n",
       "     reanalysis_sat_precip_amt_mm  reanalysis_specific_humidity_g_per_kg  \\\n",
       "930                          0.00                              13.737143   \n",
       "931                         27.19                              13.644286   \n",
       "932                          3.82                              14.662857   \n",
       "933                         16.96                              14.184286   \n",
       "934                          0.00                              13.858571   \n",
       "935                          0.00                              15.671429   \n",
       "936                         25.41                              16.651429   \n",
       "937                         60.61                              16.862857   \n",
       "938                         55.52                              17.120000   \n",
       "939                          5.60                              14.431429   \n",
       "\n",
       "     reanalysis_tdtr_k  station_avg_temp_c  station_diur_temp_rng_c  \\\n",
       "930           3.871429           25.200000                 7.042857   \n",
       "931           2.885714           25.042857                 5.785714   \n",
       "932           2.714286           26.242857                 6.814286   \n",
       "933           2.185714           25.000000                 5.714286   \n",
       "934           2.785714           25.314286                 6.242857   \n",
       "935           3.957143           27.042857                 7.514286   \n",
       "936           8.928571           26.400000                10.775000   \n",
       "937          10.314286           26.900000                11.566667   \n",
       "938           7.385714           26.800000                11.466667   \n",
       "939           9.114286           25.766667                10.533333   \n",
       "\n",
       "     station_max_temp_c  station_min_temp_c  station_precip_mm  total_cases  \n",
       "930                30.0                20.6                0.5            3  \n",
       "931                30.0                21.1                1.8            4  \n",
       "932                30.6                22.2                0.5            3  \n",
       "933                29.4                21.7               30.7            1  \n",
       "934                29.4                21.7               11.2            3  \n",
       "935                31.7                23.3                0.3            5  \n",
       "936                32.5                20.7                3.0            0  \n",
       "937                34.0                20.8               55.6            0  \n",
       "938                33.0                20.7               38.1            0  \n",
       "939                31.5                14.7               30.0            0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[930:940, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    " # The reason that checked the border line of two cities is I want to fill missing values using interpolate\n",
    "    \n",
    "df = df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                                     0\n",
       "year                                     0\n",
       "weekofyear                               0\n",
       "week_start_date                          0\n",
       "ndvi_ne                                  0\n",
       "ndvi_nw                                  0\n",
       "ndvi_se                                  0\n",
       "ndvi_sw                                  0\n",
       "precipitation_amt_mm                     0\n",
       "reanalysis_air_temp_k                    0\n",
       "reanalysis_avg_temp_k                    0\n",
       "reanalysis_dew_point_temp_k              0\n",
       "reanalysis_max_air_temp_k                0\n",
       "reanalysis_min_air_temp_k                0\n",
       "reanalysis_precip_amt_kg_per_m2          0\n",
       "reanalysis_relative_humidity_percent     0\n",
       "reanalysis_sat_precip_amt_mm             0\n",
       "reanalysis_specific_humidity_g_per_kg    0\n",
       "reanalysis_tdtr_k                        0\n",
       "station_avg_temp_c                       0\n",
       "station_diur_temp_rng_c                  0\n",
       "station_max_temp_c                       0\n",
       "station_min_temp_c                       0\n",
       "station_precip_mm                        0\n",
       "total_cases                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('total_cases', axis=1)\n",
    "y = df['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.33, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((975, 24), (481, 24))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 975 entries, 1141 to 1379\n",
      "Data columns (total 25 columns):\n",
      "city                                     975 non-null object\n",
      "year                                     975 non-null int64\n",
      "weekofyear                               975 non-null int64\n",
      "week_start_date                          975 non-null datetime64[ns]\n",
      "ndvi_ne                                  975 non-null float64\n",
      "ndvi_nw                                  975 non-null float64\n",
      "ndvi_se                                  975 non-null float64\n",
      "ndvi_sw                                  975 non-null float64\n",
      "precipitation_amt_mm                     975 non-null float64\n",
      "reanalysis_air_temp_k                    975 non-null float64\n",
      "reanalysis_avg_temp_k                    975 non-null float64\n",
      "reanalysis_dew_point_temp_k              975 non-null float64\n",
      "reanalysis_max_air_temp_k                975 non-null float64\n",
      "reanalysis_min_air_temp_k                975 non-null float64\n",
      "reanalysis_precip_amt_kg_per_m2          975 non-null float64\n",
      "reanalysis_relative_humidity_percent     975 non-null float64\n",
      "reanalysis_sat_precip_amt_mm             975 non-null float64\n",
      "reanalysis_specific_humidity_g_per_kg    975 non-null float64\n",
      "reanalysis_tdtr_k                        975 non-null float64\n",
      "station_avg_temp_c                       975 non-null float64\n",
      "station_diur_temp_rng_c                  975 non-null float64\n",
      "station_max_temp_c                       975 non-null float64\n",
      "station_min_temp_c                       975 non-null float64\n",
      "station_precip_mm                        975 non-null float64\n",
      "total_cases                              975 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(20), int64(3), object(1)\n",
      "memory usage: 198.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis=1) \n",
    "\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "df_train['week_start_date'] = pd.to_datetime(df_train['week_start_date'])\n",
    "df_test['week_start_date'] = pd.to_datetime(df_test['week_start_date'])\n",
    "\n",
    "\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train.drop(\"city\", axis=1),pd.get_dummies(df_train['city'])],axis=1)\n",
    "df_test = pd.concat([df_test.drop(\"city\", axis=1),pd.get_dummies(df_test['city'])],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(975, 24) (481, 24) (975,) (481,)\n"
     ]
    }
   ],
   "source": [
    "# re-assign X_train, test and y_train, test after missing value treatment\n",
    "X_train = df_train.drop(df_train[['total_cases','week_start_date']], axis=1)\n",
    "y_train = df_train['total_cases']\n",
    "\n",
    "X_test = df_test.drop(df_test[['total_cases','week_start_date']], axis=1)\n",
    "y_test = df_test['total_cases']\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train= y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss= StandardScaler()\n",
    "Xs_train = ss.fit_transform(X_train)\n",
    "Xs_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 975 samples, validate on 481 samples\n",
      "Epoch 1/120\n",
      "975/975 [==============================] - 0s 14us/step - loss: 24.9896 - val_loss: 22.4721\n",
      "Epoch 2/120\n",
      "975/975 [==============================] - 0s 16us/step - loss: 24.0445 - val_loss: 21.2208\n",
      "Epoch 3/120\n",
      "975/975 [==============================] - 0s 15us/step - loss: 22.6156 - val_loss: 19.4481\n",
      "Epoch 4/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 20.5876 - val_loss: 17.4487\n",
      "Epoch 5/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 18.9454 - val_loss: 16.5573\n",
      "Epoch 6/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 18.2984 - val_loss: 16.1960\n",
      "Epoch 7/120\n",
      "975/975 [==============================] - 0s 22us/step - loss: 18.0117 - val_loss: 15.9639\n",
      "Epoch 8/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 17.8471 - val_loss: 15.8049\n",
      "Epoch 9/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 17.6868 - val_loss: 15.7361\n",
      "Epoch 10/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 17.5461 - val_loss: 15.6446\n",
      "Epoch 11/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 17.4182 - val_loss: 15.5795\n",
      "Epoch 12/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 17.3034 - val_loss: 15.4538\n",
      "Epoch 13/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 17.1985 - val_loss: 15.5054\n",
      "Epoch 14/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 17.1203 - val_loss: 15.4484\n",
      "Epoch 15/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 17.0392 - val_loss: 15.4312\n",
      "Epoch 16/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 16.9743 - val_loss: 15.3712\n",
      "Epoch 17/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.9156 - val_loss: 15.3390\n",
      "Epoch 18/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.8744 - val_loss: 15.3232\n",
      "Epoch 19/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.8311 - val_loss: 15.2648\n",
      "Epoch 20/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.7922 - val_loss: 15.2323\n",
      "Epoch 21/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.7589 - val_loss: 15.2014\n",
      "Epoch 22/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.7127 - val_loss: 15.2100\n",
      "Epoch 23/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.6727 - val_loss: 15.1748\n",
      "Epoch 24/120\n",
      "975/975 [==============================] - 0s 17us/step - loss: 16.6415 - val_loss: 15.1467\n",
      "Epoch 25/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 16.6024 - val_loss: 15.1420\n",
      "Epoch 26/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 16.5520 - val_loss: 15.0852\n",
      "Epoch 27/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 16.5122 - val_loss: 15.0692\n",
      "Epoch 28/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 16.5120 - val_loss: 15.0309\n",
      "Epoch 29/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 16.4324 - val_loss: 15.0727\n",
      "Epoch 30/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 16.4157 - val_loss: 15.0480\n",
      "Epoch 31/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 16.3894 - val_loss: 15.0317\n",
      "Epoch 32/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.3362 - val_loss: 14.9935\n",
      "Epoch 33/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.3211 - val_loss: 14.9396\n",
      "Epoch 34/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 16.2672 - val_loss: 14.9641\n",
      "Epoch 35/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 16.2451 - val_loss: 14.9208\n",
      "Epoch 36/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 16.2148 - val_loss: 14.9288\n",
      "Epoch 37/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.1882 - val_loss: 14.8667\n",
      "Epoch 38/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 16.1651 - val_loss: 14.8397\n",
      "Epoch 39/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 16.1245 - val_loss: 14.8450\n",
      "Epoch 40/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 16.1027 - val_loss: 14.8208\n",
      "Epoch 41/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 16.0731 - val_loss: 14.8430\n",
      "Epoch 42/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 16.0628 - val_loss: 14.8079\n",
      "Epoch 43/120\n",
      "975/975 [==============================] - 0s 17us/step - loss: 16.0394 - val_loss: 14.7740\n",
      "Epoch 44/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.9790 - val_loss: 14.8184\n",
      "Epoch 45/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.9742 - val_loss: 14.7778\n",
      "Epoch 46/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 15.9572 - val_loss: 14.7434\n",
      "Epoch 47/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.9301 - val_loss: 14.8026\n",
      "Epoch 48/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.9117 - val_loss: 14.7576\n",
      "Epoch 49/120\n",
      "975/975 [==============================] - 0s 17us/step - loss: 15.8656 - val_loss: 14.8039\n",
      "Epoch 50/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.8799 - val_loss: 14.6718\n",
      "Epoch 51/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.8349 - val_loss: 14.7232\n",
      "Epoch 52/120\n",
      "975/975 [==============================] - 0s 17us/step - loss: 15.8100 - val_loss: 14.7444\n",
      "Epoch 53/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 15.7860 - val_loss: 14.6719\n",
      "Epoch 54/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.7410 - val_loss: 14.6926\n",
      "Epoch 55/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.7194 - val_loss: 14.6665\n",
      "Epoch 56/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.6927 - val_loss: 14.6623\n",
      "Epoch 57/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 15.6708 - val_loss: 14.7245\n",
      "Epoch 58/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 15.6559 - val_loss: 14.7423\n",
      "Epoch 59/120\n",
      "975/975 [==============================] - 0s 22us/step - loss: 15.6269 - val_loss: 14.6974\n",
      "Epoch 60/120\n",
      "975/975 [==============================] - 0s 17us/step - loss: 15.6346 - val_loss: 14.6093\n",
      "Epoch 61/120\n",
      "975/975 [==============================] - 0s 17us/step - loss: 15.6091 - val_loss: 14.6400\n",
      "Epoch 62/120\n",
      "975/975 [==============================] - 0s 16us/step - loss: 15.6044 - val_loss: 14.6187\n",
      "Epoch 63/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.5460 - val_loss: 14.6459\n",
      "Epoch 64/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 15.4949 - val_loss: 14.7288\n",
      "Epoch 65/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 15.4914 - val_loss: 14.6358\n",
      "Epoch 66/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.4865 - val_loss: 14.5521\n",
      "Epoch 67/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.4348 - val_loss: 14.6047\n",
      "Epoch 68/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 15.4052 - val_loss: 14.5862\n",
      "Epoch 69/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 15.3797 - val_loss: 14.5903\n",
      "Epoch 70/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.3688 - val_loss: 14.5990\n",
      "Epoch 71/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.3310 - val_loss: 14.5391\n",
      "Epoch 72/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 15.2963 - val_loss: 14.4815\n",
      "Epoch 73/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.3084 - val_loss: 14.5126\n",
      "Epoch 74/120\n",
      "975/975 [==============================] - 0s 17us/step - loss: 15.2659 - val_loss: 14.5959\n",
      "Epoch 75/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.2427 - val_loss: 14.5349\n",
      "Epoch 76/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 15.1961 - val_loss: 14.4266\n",
      "Epoch 77/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.1826 - val_loss: 14.4328\n",
      "Epoch 78/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 [==============================] - 0s 20us/step - loss: 15.1610 - val_loss: 14.5340\n",
      "Epoch 79/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.1374 - val_loss: 14.4559\n",
      "Epoch 80/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 15.1232 - val_loss: 14.4148\n",
      "Epoch 81/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.1002 - val_loss: 14.5554\n",
      "Epoch 82/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.1021 - val_loss: 14.4361\n",
      "Epoch 83/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 15.0480 - val_loss: 14.4372\n",
      "Epoch 84/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 15.0293 - val_loss: 14.4933\n",
      "Epoch 85/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 15.0192 - val_loss: 14.4382\n",
      "Epoch 86/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 15.0406 - val_loss: 14.4870\n",
      "Epoch 87/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 15.0157 - val_loss: 14.4042\n",
      "Epoch 88/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 14.9609 - val_loss: 14.4569\n",
      "Epoch 89/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.9206 - val_loss: 14.3282\n",
      "Epoch 90/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 14.9121 - val_loss: 14.3681\n",
      "Epoch 91/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.8900 - val_loss: 14.3627\n",
      "Epoch 92/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.8502 - val_loss: 14.3844\n",
      "Epoch 93/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 14.8411 - val_loss: 14.4018\n",
      "Epoch 94/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.8332 - val_loss: 14.3512\n",
      "Epoch 95/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 14.8494 - val_loss: 14.3188\n",
      "Epoch 96/120\n",
      "975/975 [==============================] - ETA: 0s - loss: 16.40 - 0s 18us/step - loss: 14.7951 - val_loss: 14.2959\n",
      "Epoch 97/120\n",
      "975/975 [==============================] - 0s 22us/step - loss: 14.7999 - val_loss: 14.2994\n",
      "Epoch 98/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 14.7666 - val_loss: 14.3320\n",
      "Epoch 99/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 14.7768 - val_loss: 14.3981\n",
      "Epoch 100/120\n",
      "975/975 [==============================] - 0s 22us/step - loss: 14.7313 - val_loss: 14.1863\n",
      "Epoch 101/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.6749 - val_loss: 14.3326\n",
      "Epoch 102/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 14.6872 - val_loss: 14.2006\n",
      "Epoch 103/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 14.6492 - val_loss: 14.4051\n",
      "Epoch 104/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.6097 - val_loss: 14.2774\n",
      "Epoch 105/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 14.5932 - val_loss: 14.3272\n",
      "Epoch 106/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.5720 - val_loss: 14.2484\n",
      "Epoch 107/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 14.5729 - val_loss: 14.2930\n",
      "Epoch 108/120\n",
      "975/975 [==============================] - 0s 22us/step - loss: 14.5689 - val_loss: 14.3996\n",
      "Epoch 109/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 14.5245 - val_loss: 14.3490\n",
      "Epoch 110/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 14.5105 - val_loss: 14.3687\n",
      "Epoch 111/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.4600 - val_loss: 14.3138\n",
      "Epoch 112/120\n",
      "975/975 [==============================] - 0s 21us/step - loss: 14.4383 - val_loss: 14.3343\n",
      "Epoch 113/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.4307 - val_loss: 14.5056\n",
      "Epoch 114/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 14.4618 - val_loss: 14.4271\n",
      "Epoch 115/120\n",
      "975/975 [==============================] - 0s 20us/step - loss: 14.4039 - val_loss: 14.2656\n",
      "Epoch 116/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 14.4037 - val_loss: 14.3294\n",
      "Epoch 117/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 14.3992 - val_loss: 14.4525\n",
      "Epoch 118/120\n",
      "975/975 [==============================] - 0s 18us/step - loss: 14.3485 - val_loss: 14.2899\n",
      "Epoch 119/120\n",
      "975/975 [==============================] - 0s 22us/step - loss: 14.3613 - val_loss: 14.4014\n",
      "Epoch 120/120\n",
      "975/975 [==============================] - 0s 19us/step - loss: 14.3417 - val_loss: 14.4091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12121f3c8>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(24, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "model.fit(Xs_train, y_train, validation_data=(Xs_test, y_test), epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13.35019875],\n",
       "       [ 10.30833054],\n",
       "       [ 11.67101383],\n",
       "       [  1.37324858],\n",
       "       [ 19.80879784],\n",
       "       [ 52.66710663],\n",
       "       [ 20.92783737],\n",
       "       [ 33.66841888],\n",
       "       [ 15.5451088 ],\n",
       "       [  9.93733978],\n",
       "       [ 17.88076973],\n",
       "       [  5.50292587],\n",
       "       [ 15.38540649],\n",
       "       [  6.28948689],\n",
       "       [  0.96598297],\n",
       "       [ 35.58348083],\n",
       "       [  0.75474006],\n",
       "       [ 36.53339386],\n",
       "       [  7.10054398],\n",
       "       [ 21.62678337],\n",
       "       [ 15.30698967],\n",
       "       [ 20.822258  ],\n",
       "       [  5.25020599],\n",
       "       [  6.26235247],\n",
       "       [ 46.14894867],\n",
       "       [  3.42609406],\n",
       "       [ 37.01808167],\n",
       "       [ 17.02692223],\n",
       "       [  9.22744942],\n",
       "       [  3.96792555],\n",
       "       [ 43.37912369],\n",
       "       [ 34.6515007 ],\n",
       "       [ 17.32435417],\n",
       "       [ 52.93011475],\n",
       "       [  3.26203156],\n",
       "       [ 30.27310562],\n",
       "       [ 20.95853996],\n",
       "       [ 16.89899635],\n",
       "       [ 24.16309929],\n",
       "       [ 25.12834358],\n",
       "       [  2.68453503],\n",
       "       [ 13.22915268],\n",
       "       [  2.77515221],\n",
       "       [ -1.01010227],\n",
       "       [  7.8478508 ],\n",
       "       [  6.50198269],\n",
       "       [ 32.91350555],\n",
       "       [  2.81509137],\n",
       "       [  3.31434393],\n",
       "       [  2.87704277],\n",
       "       [ 33.1889801 ],\n",
       "       [  4.23060799],\n",
       "       [ 10.06508827],\n",
       "       [  4.49755001],\n",
       "       [ 32.44622421],\n",
       "       [ 42.48340988],\n",
       "       [ 21.00075722],\n",
       "       [ 34.14570236],\n",
       "       [  3.6128633 ],\n",
       "       [ 45.47647858],\n",
       "       [  3.51741862],\n",
       "       [ 11.45859146],\n",
       "       [  8.53400612],\n",
       "       [ 25.50885963],\n",
       "       [ 25.4574585 ],\n",
       "       [ 32.91629028],\n",
       "       [ 38.36022186],\n",
       "       [ 39.01006317],\n",
       "       [ 41.15962982],\n",
       "       [ 47.0735321 ],\n",
       "       [ 39.2918396 ],\n",
       "       [ -1.15164447],\n",
       "       [  6.91608   ],\n",
       "       [  9.92177391],\n",
       "       [ 13.47977257],\n",
       "       [  6.80011606],\n",
       "       [ 38.99838638],\n",
       "       [ 22.18911362],\n",
       "       [ 41.49497223],\n",
       "       [  5.37122536],\n",
       "       [ 11.85507774],\n",
       "       [ 35.30220413],\n",
       "       [ 19.38288689],\n",
       "       [ 15.67085075],\n",
       "       [ 41.71962357],\n",
       "       [ 20.35688972],\n",
       "       [ 14.06285   ],\n",
       "       [  9.74512291],\n",
       "       [ 24.60484314],\n",
       "       [  1.92012024],\n",
       "       [ 44.01066971],\n",
       "       [  6.61429405],\n",
       "       [ 36.32128143],\n",
       "       [  6.48383522],\n",
       "       [ 15.20112038],\n",
       "       [ 35.52817535],\n",
       "       [ 36.95710754],\n",
       "       [ 25.59671974],\n",
       "       [ 25.47034836],\n",
       "       [ 13.68142796],\n",
       "       [  3.63163471],\n",
       "       [  6.68760014],\n",
       "       [ 13.04732323],\n",
       "       [ 32.74093628],\n",
       "       [ 23.07977104],\n",
       "       [ 43.94403076],\n",
       "       [  7.19036484],\n",
       "       [ 25.89873695],\n",
       "       [  5.83418465],\n",
       "       [  8.53701496],\n",
       "       [  6.52257156],\n",
       "       [ 12.21788788],\n",
       "       [  4.66755199],\n",
       "       [ 26.54651451],\n",
       "       [ 45.23291779],\n",
       "       [ 10.44984627],\n",
       "       [ 41.29052734],\n",
       "       [  2.62737417],\n",
       "       [ 19.69636345],\n",
       "       [  3.78180337],\n",
       "       [ 37.24201965],\n",
       "       [ 18.89320564],\n",
       "       [ 15.16948986],\n",
       "       [ 21.04841805],\n",
       "       [ 24.6752739 ],\n",
       "       [ -1.75373089],\n",
       "       [  0.97619879],\n",
       "       [ 10.9887619 ],\n",
       "       [ 22.07591057],\n",
       "       [ 26.11897469],\n",
       "       [  1.41533518],\n",
       "       [  7.66375208],\n",
       "       [ 27.62724304],\n",
       "       [ 18.49858284],\n",
       "       [ 25.06562614],\n",
       "       [ 25.64561653],\n",
       "       [ 10.7949543 ],\n",
       "       [ 27.83302879],\n",
       "       [ 33.25377655],\n",
       "       [  1.2771318 ],\n",
       "       [ 28.19966316],\n",
       "       [ 19.80370522],\n",
       "       [ -1.29418898],\n",
       "       [ 17.51796913],\n",
       "       [ 31.39232063],\n",
       "       [ 10.28059769],\n",
       "       [ 17.16216087],\n",
       "       [  8.03536415],\n",
       "       [ 28.65128517],\n",
       "       [ -1.99240685],\n",
       "       [ 18.69124031],\n",
       "       [ 11.21367073],\n",
       "       [ 38.62620544],\n",
       "       [ 24.57936287],\n",
       "       [  5.27862787],\n",
       "       [  6.59519386],\n",
       "       [ 44.15711975],\n",
       "       [  3.37478137],\n",
       "       [ 39.91033554],\n",
       "       [  0.82610959],\n",
       "       [  2.42353106],\n",
       "       [ 11.32337761],\n",
       "       [ 23.45126152],\n",
       "       [ 18.89108467],\n",
       "       [  7.63459969],\n",
       "       [  9.14742088],\n",
       "       [ 13.21219063],\n",
       "       [ -0.70362705],\n",
       "       [  8.35680962],\n",
       "       [ 21.88229179],\n",
       "       [ 21.18634987],\n",
       "       [ 22.81273079],\n",
       "       [ 22.31899452],\n",
       "       [  2.79572654],\n",
       "       [ 28.7713871 ],\n",
       "       [ 17.5450592 ],\n",
       "       [ 46.18379211],\n",
       "       [  3.34800315],\n",
       "       [ 16.05486107],\n",
       "       [ 39.42411041],\n",
       "       [ 44.86203766],\n",
       "       [  3.30565715],\n",
       "       [ 34.79521942],\n",
       "       [ 10.96739578],\n",
       "       [  6.03655148],\n",
       "       [ 36.83035278],\n",
       "       [ 13.29946804],\n",
       "       [  3.54468417],\n",
       "       [ 16.59906769],\n",
       "       [ 10.67943764],\n",
       "       [ 38.63976288],\n",
       "       [  1.79624879],\n",
       "       [ -1.59923315],\n",
       "       [ 54.37924957],\n",
       "       [ 35.61213684],\n",
       "       [  5.64004469],\n",
       "       [ 40.02983093],\n",
       "       [  5.19798851],\n",
       "       [ 43.54580688],\n",
       "       [ 30.78690338],\n",
       "       [  6.62591791],\n",
       "       [ 38.82119751],\n",
       "       [  5.53723192],\n",
       "       [ 24.43078995],\n",
       "       [  9.6376915 ],\n",
       "       [  8.75411034],\n",
       "       [  7.38720465],\n",
       "       [  6.45730448],\n",
       "       [ 32.57794952],\n",
       "       [  1.5809269 ],\n",
       "       [ 20.61488533],\n",
       "       [ 26.22551155],\n",
       "       [  6.66842556],\n",
       "       [  3.83247566],\n",
       "       [ 32.97237015],\n",
       "       [ 24.67569542],\n",
       "       [  3.80325603],\n",
       "       [  4.60563469],\n",
       "       [ 12.94307709],\n",
       "       [ 46.29334641],\n",
       "       [  2.97832012],\n",
       "       [  7.92800903],\n",
       "       [ 10.1286068 ],\n",
       "       [ 18.12530708],\n",
       "       [  3.1735003 ],\n",
       "       [ 30.91827583],\n",
       "       [ 25.48782539],\n",
       "       [ 24.79450417],\n",
       "       [ 42.33297729],\n",
       "       [  8.01810551],\n",
       "       [ 17.0581131 ],\n",
       "       [ 27.80648232],\n",
       "       [  8.74244308],\n",
       "       [ 19.92446518],\n",
       "       [  3.57595086],\n",
       "       [ 20.23574638],\n",
       "       [ 53.78525925],\n",
       "       [ 13.49102211],\n",
       "       [ 34.50605011],\n",
       "       [  9.44457626],\n",
       "       [  2.12142873],\n",
       "       [ 38.05749512],\n",
       "       [  5.51643229],\n",
       "       [  5.39664936],\n",
       "       [ 51.86346436],\n",
       "       [ 38.42870331],\n",
       "       [ 31.93420601],\n",
       "       [  9.36907005],\n",
       "       [  4.33413219],\n",
       "       [ 29.75575066],\n",
       "       [ -2.57354832],\n",
       "       [ 19.918396  ],\n",
       "       [ 45.95337677],\n",
       "       [  8.55033684],\n",
       "       [  6.34565401],\n",
       "       [ 19.75911331],\n",
       "       [  2.64917922],\n",
       "       [ 22.16747093],\n",
       "       [  7.12139988],\n",
       "       [ 11.02250671],\n",
       "       [ 17.71879005],\n",
       "       [  3.38545823],\n",
       "       [ 42.94778442],\n",
       "       [  9.72643471],\n",
       "       [  1.44607139],\n",
       "       [ 33.2457428 ],\n",
       "       [ 45.91942596],\n",
       "       [ 22.41382408],\n",
       "       [ 37.07978058],\n",
       "       [ 13.37259769],\n",
       "       [ 34.11339569],\n",
       "       [ 17.64341927],\n",
       "       [ 18.76346588],\n",
       "       [  8.73283005],\n",
       "       [ 10.83491611],\n",
       "       [ 21.72345543],\n",
       "       [ 25.03066063],\n",
       "       [ 43.4460907 ],\n",
       "       [  8.48036003],\n",
       "       [ 32.15242767],\n",
       "       [  7.35988331],\n",
       "       [  1.19358039],\n",
       "       [ -0.752078  ],\n",
       "       [  7.00635004],\n",
       "       [ 20.13610458],\n",
       "       [ 20.56805038],\n",
       "       [ 10.27396202],\n",
       "       [ 10.89902782],\n",
       "       [ 10.20885181],\n",
       "       [ 15.1495657 ],\n",
       "       [ 35.06581116],\n",
       "       [  4.0915041 ],\n",
       "       [ 12.15200901],\n",
       "       [ 34.04399872],\n",
       "       [ 33.58831787],\n",
       "       [  5.74533272],\n",
       "       [ 19.69851494],\n",
       "       [ 40.70951843],\n",
       "       [ 10.79119587],\n",
       "       [ 39.97489929],\n",
       "       [ 21.5545826 ],\n",
       "       [ 23.01914406],\n",
       "       [ 43.039505  ],\n",
       "       [ 17.97989464],\n",
       "       [ 30.53382301],\n",
       "       [ 13.8984499 ],\n",
       "       [ 31.89258575],\n",
       "       [  1.23616409],\n",
       "       [  1.64062738],\n",
       "       [ 30.88025093],\n",
       "       [  3.75217199],\n",
       "       [ 14.45820427],\n",
       "       [ 52.31181717],\n",
       "       [ 49.1241951 ],\n",
       "       [  5.88297176],\n",
       "       [  6.99465084],\n",
       "       [ 31.37509727],\n",
       "       [  4.22576714],\n",
       "       [  0.74043494],\n",
       "       [ 26.42677879],\n",
       "       [  3.83978605],\n",
       "       [ 19.18298912],\n",
       "       [ 15.37615204],\n",
       "       [ 36.30999374],\n",
       "       [ 40.5790596 ],\n",
       "       [ 44.25069427],\n",
       "       [ 25.49405098],\n",
       "       [  4.96032047],\n",
       "       [ 16.04926109],\n",
       "       [  5.19368362],\n",
       "       [ 40.98055267],\n",
       "       [ 50.99967194],\n",
       "       [ 21.17502403],\n",
       "       [ 20.25324631],\n",
       "       [ 41.29071808],\n",
       "       [ 41.16140366],\n",
       "       [  2.93545818],\n",
       "       [ 30.33806038],\n",
       "       [ 43.69664001],\n",
       "       [ 33.49703979],\n",
       "       [  4.30504751],\n",
       "       [ 28.74605751],\n",
       "       [ 31.73782349],\n",
       "       [ 26.48290062],\n",
       "       [ 20.38830566],\n",
       "       [  6.32960081],\n",
       "       [ 31.64222145],\n",
       "       [  5.71007824],\n",
       "       [ 12.72290039],\n",
       "       [ 29.26162148],\n",
       "       [  4.54181767],\n",
       "       [ 17.42688179],\n",
       "       [ 41.49378204],\n",
       "       [ -0.26027212],\n",
       "       [  6.50989342],\n",
       "       [  7.74407005],\n",
       "       [  7.48596287],\n",
       "       [  4.64768648],\n",
       "       [ 45.46189117],\n",
       "       [  5.73964214],\n",
       "       [ 17.37275887],\n",
       "       [ 20.47758102],\n",
       "       [ 14.29064178],\n",
       "       [  4.03939247],\n",
       "       [ 43.47511673],\n",
       "       [ 20.66530609],\n",
       "       [ 32.44658661],\n",
       "       [ 39.55936432],\n",
       "       [ 38.00715637],\n",
       "       [ 18.57604027],\n",
       "       [ 37.36842728],\n",
       "       [ 31.80150032],\n",
       "       [ 10.3891983 ],\n",
       "       [ 10.92953396],\n",
       "       [  1.08092594],\n",
       "       [ 30.375494  ],\n",
       "       [ 18.73249054],\n",
       "       [ -0.48074862],\n",
       "       [ 24.90473747],\n",
       "       [ 18.86517525],\n",
       "       [ 51.57096863],\n",
       "       [  8.06393623],\n",
       "       [ 40.68325806],\n",
       "       [ 47.26318741],\n",
       "       [ 15.47362328],\n",
       "       [  1.17155802],\n",
       "       [ 59.15287018],\n",
       "       [ 38.35583878],\n",
       "       [ 14.22956657],\n",
       "       [ 27.44642448],\n",
       "       [ 29.80756569],\n",
       "       [  3.27973461],\n",
       "       [  2.33085179],\n",
       "       [ 12.5866518 ],\n",
       "       [ 12.0229702 ],\n",
       "       [  5.13837719],\n",
       "       [ 17.77235031],\n",
       "       [  8.0246439 ],\n",
       "       [ 48.17929459],\n",
       "       [ 35.41733551],\n",
       "       [  6.02700043],\n",
       "       [ 33.25409698],\n",
       "       [ 15.55078888],\n",
       "       [  8.75762844],\n",
       "       [  7.3506813 ],\n",
       "       [ 42.16468811],\n",
       "       [  5.15306854],\n",
       "       [ 10.37605381],\n",
       "       [ 41.92927551],\n",
       "       [  0.74688584],\n",
       "       [ 15.74227142],\n",
       "       [ 24.67255402],\n",
       "       [ 48.28821564],\n",
       "       [  4.80849934],\n",
       "       [  3.66085243],\n",
       "       [  6.3902626 ],\n",
       "       [ 13.87262154],\n",
       "       [  3.19989681],\n",
       "       [  9.53824043],\n",
       "       [ 30.19904327],\n",
       "       [  9.4178257 ],\n",
       "       [  7.3734026 ],\n",
       "       [ 11.45606518],\n",
       "       [ 18.12117004],\n",
       "       [ 15.09302807],\n",
       "       [  1.12948382],\n",
       "       [ 23.37075806],\n",
       "       [  5.04708433],\n",
       "       [ 21.07990074],\n",
       "       [ 19.4473629 ],\n",
       "       [ 37.95724487],\n",
       "       [ 29.52338028],\n",
       "       [ 10.95288372],\n",
       "       [ 32.35189056],\n",
       "       [ 32.75244522],\n",
       "       [  4.50750256],\n",
       "       [ 24.12716866],\n",
       "       [ 24.36883926],\n",
       "       [ 26.78724098],\n",
       "       [  6.46964741],\n",
       "       [  4.51029587],\n",
       "       [  2.97282076],\n",
       "       [  2.32414484],\n",
       "       [  7.95072317],\n",
       "       [  0.47107008],\n",
       "       [ 41.69296646],\n",
       "       [ 41.14546204],\n",
       "       [ 43.05386353],\n",
       "       [  6.43263531],\n",
       "       [  2.29563332],\n",
       "       [  8.3434906 ],\n",
       "       [  3.44785333],\n",
       "       [ -0.45454308],\n",
       "       [ 34.64509583],\n",
       "       [ 11.34326935],\n",
       "       [ 19.86347008],\n",
       "       [  4.02120018],\n",
       "       [ 27.38732338],\n",
       "       [ 13.38192844],\n",
       "       [  0.60709685],\n",
       "       [ 24.1842289 ],\n",
       "       [  6.38312912],\n",
       "       [  6.24843073],\n",
       "       [  4.0369873 ],\n",
       "       [  4.67865992],\n",
       "       [  4.2982192 ],\n",
       "       [ 14.84189987],\n",
       "       [ 24.13868523],\n",
       "       [  8.05430984],\n",
       "       [  7.20564747],\n",
       "       [  4.7685585 ],\n",
       "       [ 10.37866879],\n",
       "       [ 49.77337646],\n",
       "       [ 24.52994347],\n",
       "       [  2.1937449 ],\n",
       "       [  4.71493149],\n",
       "       [  3.68920708],\n",
       "       [  9.89609623],\n",
       "       [ 23.91776848],\n",
       "       [ 50.51027679],\n",
       "       [ 22.10920906]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(Xs_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAETCAYAAADUAmpRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBVUGiqIoCvD/AXqv2KkPzw2NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114688278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(y_pred,y_test, alpha=.75,\n",
    "            color='b') #alpha helps to show overlapping data\n",
    "plt.xlabel('Predicted cases')\n",
    "plt.ylabel('Actual cases')\n",
    "plt.title('CNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"dengue_features_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission= pd.DataFrame()\n",
    "submission['city'] = test.city\n",
    "submission['year'] = test.year\n",
    "submission['weekofyear']=test.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(test._get_numeric_data())\n",
    "for feature in features:\n",
    "    test[feature] = test.groupby('city')[feature].transform(lambda x:x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.concat([test.drop(\"city\", axis=1),pd.get_dummies(test['city'])],axis=1)  \n",
    "\n",
    "test = test.drop('week_start_date',axis=1)\n",
    "\n",
    "test_s = ss.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission['total_cases'] = model.predict(test_s).round()\n",
    "\n",
    "submission.total_cases = submission.total_cases.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear  total_cases\n",
       "0   sj  2008          18            4\n",
       "1   sj  2008          19            2\n",
       "2   sj  2008          20            6\n",
       "3   sj  2008          21            9\n",
       "4   sj  2008          22            7"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_second_with_cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is score, 29.9087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM RNN Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_df =df[df['city']=='iq'] \n",
    "\n",
    "iq_df = iq_df[['week_start_date','total_cases']]\n",
    "\n",
    "iq_df.set_index('week_start_date', inplace=True)\n",
    "\n",
    "\n",
    "iq_df.sort_index(ascending=True, inplace=True)\n",
    "iq_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_df =df[df['city']=='sj'] \n",
    "\n",
    "sj_df = sj_df[['week_start_date','total_cases']]\n",
    "\n",
    "sj_df.set_index('week_start_date', inplace=True)\n",
    "\n",
    "\n",
    "sj_df.sort_index(ascending=True, inplace=True)\n",
    "sj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_start_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-07-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-08</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_cases\n",
       "week_start_date             \n",
       "2000-07-01                 0\n",
       "2000-07-08                 0\n",
       "2000-07-15                 0\n",
       "2000-07-22                 0\n",
       "2000-07-29                 0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_df =df[df['city']=='iq'] \n",
    "\n",
    "iq_df = iq_df[['week_start_date','total_cases']]\n",
    "\n",
    "iq_df.set_index('week_start_date', inplace=True)\n",
    "\n",
    "\n",
    "iq_df.sort_index(ascending=True, inplace=True)\n",
    "iq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_X = iq_df[['total_cases']].shift(1)[1:]\n",
    "iq_y = iq_df['total_cases'].values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "         0,   1,   1,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   1,   0,   0,   0,   0,   1,   1,   0,   0,   1,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   1,   1,   1,   2,   4,   1,   4,\n",
       "        11,  16,  23,  12,  14,  18,   8,   7,  10,   7,  10,   5,  11,\n",
       "         8,  18,  13,   9,  22,  10,   5,  13,   2,  11,  11,   3,   7,\n",
       "         7,   4,   5,   6,   7,   7,   4,   9,  17,   8,  22,  18,  21,\n",
       "        16,  31,  25,  28,  26,  18,  27,  11,  38,  29,  21,  11,  10,\n",
       "         5,   6,   2,   1,   2,   2,   3,   5,   1,   4,   2,   4,   0,\n",
       "         0,   0,   0,   1,   1,   1,   1,   1,   2,   3,   4,   6,   2,\n",
       "         2,   5,   1,   1,   0,   0,   0,   0,   2,   0,   3,   0,   0,\n",
       "         0,   2,   2,   3,   3,   3,   1,   2,   3,   6,   5,   1,   4,\n",
       "         5,   8,   5,   2,   3,   3,   1,   6,   4,   1,   2,   3,   1,\n",
       "         8,   4,   6,   7,   5,   8,   6,   5,   6,   6,  13,   2,  10,\n",
       "         3,  12,   7,   6,   5,   6,   6,   6,   8,   6,   9,  12,  19,\n",
       "         8,  16,  21,   6,  22,  37,  33,  18,  83, 116,  32,   7,   9,\n",
       "        10,   5,   8,   7,   8,  11,   6,   7,   7,  14,   7,   9,  13,\n",
       "        16,   7,   9,   2,  13,   8,   3,   5,   4,   8,   2,   3,   5,\n",
       "         7,   3,   5,   6,   5,   5,   4,   0,   0,   0,   0,   0,   2,\n",
       "         4,   4,   3,   3,   5,   6,  14,   3,   7,  11,   2,   6,   8,\n",
       "        25,  21,  10,  28,  39,  20,  24,  28,  26,   8,   9,  12,  18,\n",
       "         9,   9,   6,   6,   8,   5,   7,   6,   5,   3,   1,   0,   1,\n",
       "         2,   3,   2,   2,   2,   2,   2,   4,   0,   6,   3,   2,   6,\n",
       "         2,   7,   4,   6,   6,   2,  13,  10,   5,   2,   0,   1,   0,\n",
       "        14,   6,  10,   5,  12,   9,   5,  11,   2,   6,   7,   6,   5,\n",
       "         9,   5,   8,   3,   4,  11,   5,   8,   4,   3,   1,   2,   3,\n",
       "         4,   1,   8,   5,   3,   2,   7,   1,   6,   7,   5,   2,   6,\n",
       "        11,   6,   3,  11,  11,   5,   4,   9,  23,  28,  26,   7,  29,\n",
       "        58,  26,  38,  35,  37,  20,  29,  25,  23,   9,   3,   6,   6,\n",
       "         3,   1,   3,   1,   1,   0,   2,   1,   1,   0,   0,   1,   0,\n",
       "         3,   3,   1,   5,   2,   5,   5,   5,   9,  17,  19,  25,  45,\n",
       "        34,  63,  44,  50,  35,  16,  16,  13,   9,  15,   4,   0,   1,\n",
       "        10,  11,  29,  35,  30,  20,  21,  12,   9,  11,   9,   5,  11,\n",
       "         3,   5,   5,   4,   4,   1,   0,   2,   3,   3,   5,   2,   1,\n",
       "         2,   0,   0,   3,   5,   5,   7,   5,   2,   2,   2,   0,   2,\n",
       "         1,   1,   2,   2,   3,   9,   5,   5,   4,   4,   1,   0,   0,\n",
       "        10,   9,  17,  16,  11,  12,  19,  15,  12,  12,  16,   9,   4,\n",
       "         9,   6,   8,   4,   2,   7,   6,   5,   8,   1,   1,   4])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "iq_X_t = mm.fit_transform(iq_X)\n",
    "\n",
    "iq_y_t = mm.transform([iq_y])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_train_size = int(len(iq_X_t) * .67)\n",
    "iq_train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_X_train = iq_X_t[:iq_train_size, :]\n",
    "iq_X_train = iq_X_train.reshape(iq_X_train.shape[0], 1, iq_X_train.shape[1])\n",
    "iq_y_train = iq_y_t[:iq_train_size]\n",
    "\n",
    "iq_X_test = iq_X_t[iq_train_size:, :]\n",
    "iq_X_test = iq_X_test.reshape(iq_X_test.shape[0], 1, iq_X_test.shape[1])\n",
    "iq_y_test = iq_y_t[iq_train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.09482759]],\n",
       "\n",
       "       [[ 0.13793103]],\n",
       "\n",
       "       [[ 0.19827586]],\n",
       "\n",
       "       [[ 0.10344828]],\n",
       "\n",
       "       [[ 0.12068966]],\n",
       "\n",
       "       [[ 0.15517241]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.09482759]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.15517241]],\n",
       "\n",
       "       [[ 0.11206897]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.18965517]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.11206897]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.09482759]],\n",
       "\n",
       "       [[ 0.09482759]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.14655172]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.18965517]],\n",
       "\n",
       "       [[ 0.15517241]],\n",
       "\n",
       "       [[ 0.18103448]],\n",
       "\n",
       "       [[ 0.13793103]],\n",
       "\n",
       "       [[ 0.26724138]],\n",
       "\n",
       "       [[ 0.21551724]],\n",
       "\n",
       "       [[ 0.24137931]],\n",
       "\n",
       "       [[ 0.22413793]],\n",
       "\n",
       "       [[ 0.15517241]],\n",
       "\n",
       "       [[ 0.23275862]],\n",
       "\n",
       "       [[ 0.09482759]],\n",
       "\n",
       "       [[ 0.32758621]],\n",
       "\n",
       "       [[ 0.25      ]],\n",
       "\n",
       "       [[ 0.18103448]],\n",
       "\n",
       "       [[ 0.09482759]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.11206897]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.10344828]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.10344828]],\n",
       "\n",
       "       [[ 0.1637931 ]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.13793103]],\n",
       "\n",
       "       [[ 0.18103448]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.18965517]],\n",
       "\n",
       "       [[ 0.31896552]],\n",
       "\n",
       "       [[ 0.28448276]],\n",
       "\n",
       "       [[ 0.15517241]],\n",
       "\n",
       "       [[ 0.71551724]],\n",
       "\n",
       "       [[ 1.        ]],\n",
       "\n",
       "       [[ 0.27586207]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.09482759]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.12068966]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.11206897]],\n",
       "\n",
       "       [[ 0.13793103]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.11206897]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.12068966]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.09482759]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.21551724]],\n",
       "\n",
       "       [[ 0.18103448]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.24137931]],\n",
       "\n",
       "       [[ 0.3362069 ]],\n",
       "\n",
       "       [[ 0.17241379]],\n",
       "\n",
       "       [[ 0.20689655]],\n",
       "\n",
       "       [[ 0.24137931]],\n",
       "\n",
       "       [[ 0.22413793]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.10344828]],\n",
       "\n",
       "       [[ 0.15517241]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.06896552]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.02586207]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.06034483]],\n",
       "\n",
       "       [[ 0.03448276]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.11206897]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.01724138]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.00862069]],\n",
       "\n",
       "       [[ 0.        ]],\n",
       "\n",
       "       [[ 0.12068966]],\n",
       "\n",
       "       [[ 0.05172414]],\n",
       "\n",
       "       [[ 0.0862069 ]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.10344828]],\n",
       "\n",
       "       [[ 0.07758621]],\n",
       "\n",
       "       [[ 0.04310345]],\n",
       "\n",
       "       [[ 0.09482759]]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 347 samples, validate on 172 samples\n",
      "Epoch 1/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0597\n",
      "Epoch 2/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0451 - val_loss: 0.0544\n",
      "Epoch 3/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0506\n",
      "Epoch 4/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.0510\n",
      "Epoch 5/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0422\n",
      "Epoch 6/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.0397\n",
      "Epoch 7/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0333 - val_loss: 0.0383\n",
      "Epoch 8/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.0365\n",
      "Epoch 9/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0318 - val_loss: 0.0356\n",
      "Epoch 10/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0358\n",
      "Epoch 11/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0369\n",
      "Epoch 12/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0372\n",
      "Epoch 13/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0315 - val_loss: 0.0382\n",
      "Epoch 14/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0358\n",
      "Epoch 15/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0361\n",
      "Epoch 16/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0365\n",
      "Epoch 17/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0354\n",
      "Epoch 18/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0315 - val_loss: 0.0371\n",
      "Epoch 19/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0315 - val_loss: 0.0356\n",
      "Epoch 20/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0371\n",
      "Epoch 21/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.0362\n",
      "Epoch 22/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0354\n",
      "Epoch 23/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0354\n",
      "Epoch 24/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0379\n",
      "Epoch 25/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0356\n",
      "Epoch 26/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0353\n",
      "Epoch 27/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0355\n",
      "Epoch 28/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.0358\n",
      "Epoch 29/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0360\n",
      "Epoch 30/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0357\n",
      "Epoch 31/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0362\n",
      "Epoch 32/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0356\n",
      "Epoch 33/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0354\n",
      "Epoch 34/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0353\n",
      "Epoch 35/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0354\n",
      "Epoch 36/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0364\n",
      "Epoch 37/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0378\n",
      "Epoch 38/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0358\n",
      "Epoch 39/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0369\n",
      "Epoch 40/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0370\n",
      "Epoch 41/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0353\n",
      "Epoch 42/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.0363\n",
      "Epoch 43/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0355\n",
      "Epoch 44/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0364\n",
      "Epoch 45/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0352\n",
      "Epoch 46/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0353\n",
      "Epoch 47/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0367\n",
      "Epoch 48/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0352\n",
      "Epoch 49/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0354\n",
      "Epoch 50/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0365\n",
      "Epoch 51/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0354\n",
      "Epoch 52/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0356\n",
      "Epoch 53/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0370\n",
      "Epoch 54/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0352\n",
      "Epoch 55/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0360\n",
      "Epoch 56/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0353\n",
      "Epoch 57/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0360\n",
      "Epoch 58/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0351\n",
      "Epoch 59/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0358\n",
      "Epoch 60/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0350\n",
      "Epoch 61/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.0361\n",
      "Epoch 62/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0350\n",
      "Epoch 63/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0353\n",
      "Epoch 64/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0353\n",
      "Epoch 65/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0362\n",
      "Epoch 66/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0350\n",
      "Epoch 67/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0351\n",
      "Epoch 68/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0350\n",
      "Epoch 69/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0350\n",
      "Epoch 70/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0352\n",
      "Epoch 71/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0350\n",
      "Epoch 72/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0352\n",
      "Epoch 73/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0351\n",
      "Epoch 74/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0351\n",
      "Epoch 75/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0350\n",
      "Epoch 76/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0357\n",
      "Epoch 77/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0353\n",
      "Epoch 78/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.0357\n",
      "Epoch 79/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0361\n",
      "Epoch 80/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0349\n",
      "Epoch 82/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0354\n",
      "Epoch 83/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0350\n",
      "Epoch 84/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0351\n",
      "Epoch 85/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0350\n",
      "Epoch 86/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0358\n",
      "Epoch 87/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0357\n",
      "Epoch 88/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0365\n",
      "Epoch 89/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0357\n",
      "Epoch 90/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0350\n",
      "Epoch 91/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0360\n",
      "Epoch 92/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0352\n",
      "Epoch 93/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0356\n",
      "Epoch 94/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0366\n",
      "Epoch 95/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0359\n",
      "Epoch 96/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0301 - val_loss: 0.0357\n",
      "Epoch 97/100\n",
      "347/347 [==============================] - 0s 993us/step - loss: 0.0302 - val_loss: 0.0354\n",
      "Epoch 98/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0353\n",
      "Epoch 99/100\n",
      "347/347 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0352\n",
      "Epoch 100/100\n",
      "347/347 [==============================] - 0s 967us/step - loss: 0.0305 - val_loss: 0.0353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1297ea9b0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_model = Sequential()\n",
    "iq_model.add(LSTM(2, input_shape=(None,1)))\n",
    "iq_model.add(Dense(1))\n",
    "iq_model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "iq_model.fit(iq_X_train, iq_y_train, epochs=100, batch_size=1, validation_data=(iq_X_test, iq_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_pred = iq_model.predict(iq_X_test)\n",
    "iq_pred_t = mm.inverse_transform(iq_pred)\n",
    "\n",
    "\n",
    "iq_pred_t=iq_pred_t.round()\n",
    "\n",
    "\n",
    "\n",
    "print(mean_absolute_error(iq_pred_t, iq_y[iq_train_size:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_start_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-04-30</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-07</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-14</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-21</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-28</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_cases\n",
       "week_start_date             \n",
       "1990-04-30                 4\n",
       "1990-05-07                 5\n",
       "1990-05-14                 4\n",
       "1990-05-21                 3\n",
       "1990-05-28                 6"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_df =df[df['city']=='sj'] \n",
    "\n",
    "sj_df = sj_df[['week_start_date','total_cases']]\n",
    "\n",
    "sj_df.set_index('week_start_date', inplace=True)\n",
    "\n",
    "\n",
    "sj_df.sort_index(ascending=True, inplace=True)\n",
    "sj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_X = sj_df[['total_cases']].shift(1)[1:]\n",
    "sj_y = sj_df['total_cases'].values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "sj_X_t = mm.fit_transform(sj_X)\n",
    "\n",
    "sj_y_t = mm.transform([sj_y])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_train_size = int(len(sj_X) * .67)\n",
    "sj_train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_X_train = sj_X_t[:sj_train_size, :]\n",
    "sj_X_train = sj_X_train.reshape(sj_X_train.shape[0], 1, sj_X_train.shape[1])\n",
    "sj_y_train = sj_y_t[:sj_train_size]\n",
    "\n",
    "sj_X_test = sj_X_t[sj_train_size:, :]\n",
    "sj_X_test = sj_X_test.reshape(sj_X_test.shape[0], 1, sj_X_test.shape[1])\n",
    "sj_y_test = sj_y_t[sj_train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 626 samples, validate on 309 samples\n",
      "Epoch 1/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0479 - val_loss: 0.0236\n",
      "Epoch 2/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0232 - val_loss: 0.0121\n",
      "Epoch 3/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0122\n",
      "Epoch 4/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 5/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0128\n",
      "Epoch 6/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0126\n",
      "Epoch 7/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0122\n",
      "Epoch 9/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0125\n",
      "Epoch 10/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0145\n",
      "Epoch 11/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0131\n",
      "Epoch 12/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0148\n",
      "Epoch 13/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0121\n",
      "Epoch 14/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0148\n",
      "Epoch 15/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0136\n",
      "Epoch 16/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0130\n",
      "Epoch 17/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0206 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0127\n",
      "Epoch 19/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0128\n",
      "Epoch 20/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0206 - val_loss: 0.0129\n",
      "Epoch 21/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 22/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0120\n",
      "Epoch 23/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0129\n",
      "Epoch 24/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0122\n",
      "Epoch 25/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0142\n",
      "Epoch 26/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0123\n",
      "Epoch 27/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0206 - val_loss: 0.0137\n",
      "Epoch 28/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0191\n",
      "Epoch 30/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0148\n",
      "Epoch 31/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0121\n",
      "Epoch 32/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0137\n",
      "Epoch 33/100\n",
      "626/626 [==============================] - 1s 988us/step - loss: 0.0203 - val_loss: 0.0122\n",
      "Epoch 34/100\n",
      "626/626 [==============================] - 1s 930us/step - loss: 0.0200 - val_loss: 0.0135\n",
      "Epoch 35/100\n",
      "626/626 [==============================] - 1s 893us/step - loss: 0.0204 - val_loss: 0.0123\n",
      "Epoch 36/100\n",
      "626/626 [==============================] - 1s 901us/step - loss: 0.0201 - val_loss: 0.0140\n",
      "Epoch 37/100\n",
      "626/626 [==============================] - 1s 881us/step - loss: 0.0203 - val_loss: 0.0134\n",
      "Epoch 38/100\n",
      "626/626 [==============================] - 1s 946us/step - loss: 0.0201 - val_loss: 0.0123\n",
      "Epoch 39/100\n",
      "626/626 [==============================] - 1s 869us/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 40/100\n",
      "626/626 [==============================] - 1s 922us/step - loss: 0.0201 - val_loss: 0.0140\n",
      "Epoch 41/100\n",
      "626/626 [==============================] - 1s 955us/step - loss: 0.0205 - val_loss: 0.0121\n",
      "Epoch 42/100\n",
      "626/626 [==============================] - 1s 922us/step - loss: 0.0202 - val_loss: 0.0126\n",
      "Epoch 43/100\n",
      "626/626 [==============================] - 1s 933us/step - loss: 0.0201 - val_loss: 0.0147\n",
      "Epoch 44/100\n",
      "626/626 [==============================] - 1s 921us/step - loss: 0.0202 - val_loss: 0.0126\n",
      "Epoch 45/100\n",
      "626/626 [==============================] - 1s 954us/step - loss: 0.0205 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "626/626 [==============================] - 1s 956us/step - loss: 0.0203 - val_loss: 0.0133\n",
      "Epoch 47/100\n",
      "626/626 [==============================] - 1s 998us/step - loss: 0.0201 - val_loss: 0.0138\n",
      "Epoch 48/100\n",
      "626/626 [==============================] - 1s 989us/step - loss: 0.0203 - val_loss: 0.0121\n",
      "Epoch 49/100\n",
      "626/626 [==============================] - 1s 920us/step - loss: 0.0202 - val_loss: 0.0128\n",
      "Epoch 50/100\n",
      "626/626 [==============================] - 1s 868us/step - loss: 0.0205 - val_loss: 0.0136\n",
      "Epoch 51/100\n",
      "626/626 [==============================] - 1s 961us/step - loss: 0.0204 - val_loss: 0.0124\n",
      "Epoch 52/100\n",
      "626/626 [==============================] - 1s 886us/step - loss: 0.0202 - val_loss: 0.0122\n",
      "Epoch 53/100\n",
      "626/626 [==============================] - 1s 883us/step - loss: 0.0202 - val_loss: 0.0128\n",
      "Epoch 54/100\n",
      "626/626 [==============================] - 1s 881us/step - loss: 0.0202 - val_loss: 0.0129\n",
      "Epoch 55/100\n",
      "626/626 [==============================] - 1s 906us/step - loss: 0.0202 - val_loss: 0.0135\n",
      "Epoch 56/100\n",
      "626/626 [==============================] - 1s 889us/step - loss: 0.0204 - val_loss: 0.0122\n",
      "Epoch 57/100\n",
      "626/626 [==============================] - 1s 987us/step - loss: 0.0207 - val_loss: 0.0122\n",
      "Epoch 58/100\n",
      "626/626 [==============================] - 1s 979us/step - loss: 0.0203 - val_loss: 0.0121\n",
      "Epoch 59/100\n",
      "626/626 [==============================] - 1s 928us/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 60/100\n",
      "626/626 [==============================] - 1s 972us/step - loss: 0.0203 - val_loss: 0.0134\n",
      "Epoch 61/100\n",
      "626/626 [==============================] - 1s 993us/step - loss: 0.0205 - val_loss: 0.0128\n",
      "Epoch 62/100\n",
      "626/626 [==============================] - 1s 943us/step - loss: 0.0202 - val_loss: 0.0126\n",
      "Epoch 63/100\n",
      "626/626 [==============================] - 1s 915us/step - loss: 0.0203 - val_loss: 0.0146\n",
      "Epoch 64/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0136\n",
      "Epoch 65/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0121\n",
      "Epoch 66/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0122\n",
      "Epoch 67/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 68/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0135\n",
      "Epoch 69/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0125\n",
      "Epoch 70/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0140\n",
      "Epoch 71/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 72/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0125\n",
      "Epoch 73/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0127\n",
      "Epoch 74/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0125\n",
      "Epoch 75/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0122\n",
      "Epoch 76/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0155\n",
      "Epoch 77/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0132\n",
      "Epoch 78/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0138\n",
      "Epoch 79/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0123\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0132\n",
      "Epoch 81/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0130\n",
      "Epoch 82/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0124\n",
      "Epoch 83/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0138\n",
      "Epoch 84/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0205 - val_loss: 0.0143\n",
      "Epoch 85/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0128\n",
      "Epoch 86/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0131\n",
      "Epoch 87/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0128\n",
      "Epoch 88/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0122\n",
      "Epoch 89/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0141\n",
      "Epoch 90/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0123\n",
      "Epoch 91/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0133\n",
      "Epoch 92/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0122\n",
      "Epoch 93/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0124\n",
      "Epoch 94/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0123\n",
      "Epoch 95/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0126\n",
      "Epoch 96/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0202 - val_loss: 0.0130\n",
      "Epoch 97/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.0125\n",
      "Epoch 98/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.0163\n",
      "Epoch 99/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0164\n",
      "Epoch 100/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.0203 - val_loss: 0.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c3bde10>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_model = Sequential()\n",
    "sj_model.add(LSTM(10, input_shape=(None,1)))\n",
    "sj_model.add(Dense(1))\n",
    "sj_model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "sj_model.fit(sj_X_train, sj_y_train, epochs=100, batch_size=1, validation_data=(sj_X_test, sj_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.73462783172\n"
     ]
    }
   ],
   "source": [
    "sj_pred = sj_model.predict(sj_X_test)\n",
    "sj_pred_t = mm.inverse_transform(sj_pred)\n",
    "\n",
    "\n",
    "sj_pred_t=sj_pred_t.round()\n",
    "\n",
    "\n",
    "\n",
    "print(mean_absolute_error(sj_pred_t, sj_y[sj_train_size:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAETCAYAAAA/NdFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ddc7358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iq_pred,iq_y_test, alpha=.75,\n",
    "            color='r')\n",
    "plt.scatter(sj_pred,sj_y_test, alpha=.75,\n",
    "            color='b') #alpha helps to show overlapping data\n",
    "plt.xlabel('Predicted cases')\n",
    "plt.ylabel('Actual cases')\n",
    "plt.title('LSTM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"dengue_features_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission= pd.DataFrame()\n",
    "submission['city'] = test.city\n",
    "submission['year'] = test.year\n",
    "submission['weekofyear']=test.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_df =df[df['city']=='iq'] \n",
    "\n",
    "iq_df = iq_df[['week_start_date','total_cases']]\n",
    "\n",
    "iq_df.set_index('week_start_date', inplace=True)\n",
    "\n",
    "\n",
    "iq_df.sort_index(ascending=True, inplace=True)\n",
    "len(iq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_test =test[test['city']=='iq'] \n",
    "iq_test = iq_test[['week_start_date']]\n",
    "iq_test.set_index('week_start_date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_df_new = pd.concat([iq_df, iq_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_X = iq_df_new[['total_cases']].shift(1)[1:]\n",
    "iq_y = iq_df_new['total_cases'].values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-efe09aff15cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miq_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jasonjklim/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonjklim/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonjklim/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         X = check_array(X, copy=self.copy, warn_on_dtype=True,\n\u001b[0;32m--> 334\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonjklim/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonjklim/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "mm.fit_transform(iq_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_X_train = iq_X.iloc[:520, :]\n",
    "\n",
    "iq_y_train = iq_y[:520]\n",
    "\n",
    "iq_X_test = iq_X.iloc[520:, :]\n",
    "\n",
    "iq_y_test = iq_y[520:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_start_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-07-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-06</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-13</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-20</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-27</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-17</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-17</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-07</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-14</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-21</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-18</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-25</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-06</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-13</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-20</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-27</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-17</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-17</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-18</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-25</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-06</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-13</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-20</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-27</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-17</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-14</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-21</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-18</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-25</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-19</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-09</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-16</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-07</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-14</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-21</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-18</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-25</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_cases\n",
       "week_start_date             \n",
       "2010-07-09               NaN\n",
       "2010-07-16               NaN\n",
       "2010-07-23               NaN\n",
       "2010-07-30               NaN\n",
       "2010-08-06               NaN\n",
       "2010-08-13               NaN\n",
       "2010-08-20               NaN\n",
       "2010-08-27               NaN\n",
       "2010-09-03               NaN\n",
       "2010-09-10               NaN\n",
       "2010-09-17               NaN\n",
       "2010-09-24               NaN\n",
       "2010-10-01               NaN\n",
       "2010-10-08               NaN\n",
       "2010-10-15               NaN\n",
       "2010-10-22               NaN\n",
       "2010-10-29               NaN\n",
       "2010-11-05               NaN\n",
       "2010-11-12               NaN\n",
       "2010-11-19               NaN\n",
       "2010-11-26               NaN\n",
       "2010-12-03               NaN\n",
       "2010-12-10               NaN\n",
       "2010-12-17               NaN\n",
       "2010-12-24               NaN\n",
       "2011-01-01               NaN\n",
       "2011-01-08               NaN\n",
       "2011-01-15               NaN\n",
       "2011-01-22               NaN\n",
       "2011-01-29               NaN\n",
       "2011-02-05               NaN\n",
       "2011-02-12               NaN\n",
       "2011-02-19               NaN\n",
       "2011-02-26               NaN\n",
       "2011-03-05               NaN\n",
       "2011-03-12               NaN\n",
       "2011-03-19               NaN\n",
       "2011-03-26               NaN\n",
       "2011-04-02               NaN\n",
       "2011-04-09               NaN\n",
       "2011-04-16               NaN\n",
       "2011-04-23               NaN\n",
       "2011-04-30               NaN\n",
       "2011-05-07               NaN\n",
       "2011-05-14               NaN\n",
       "2011-05-21               NaN\n",
       "2011-05-28               NaN\n",
       "2011-06-04               NaN\n",
       "2011-06-11               NaN\n",
       "2011-06-18               NaN\n",
       "2011-06-25               NaN\n",
       "2011-07-02               NaN\n",
       "2011-07-09               NaN\n",
       "2011-07-16               NaN\n",
       "2011-07-23               NaN\n",
       "2011-07-30               NaN\n",
       "2011-08-06               NaN\n",
       "2011-08-13               NaN\n",
       "2011-08-20               NaN\n",
       "2011-08-27               NaN\n",
       "2011-09-03               NaN\n",
       "2011-09-10               NaN\n",
       "2011-09-17               NaN\n",
       "2011-09-24               NaN\n",
       "2011-10-01               NaN\n",
       "2011-10-08               NaN\n",
       "2011-10-15               NaN\n",
       "2011-10-22               NaN\n",
       "2011-10-29               NaN\n",
       "2011-11-05               NaN\n",
       "2011-11-12               NaN\n",
       "2011-11-19               NaN\n",
       "2011-11-26               NaN\n",
       "2011-12-03               NaN\n",
       "2011-12-10               NaN\n",
       "2011-12-17               NaN\n",
       "2011-12-24               NaN\n",
       "2012-01-01               NaN\n",
       "2012-01-08               NaN\n",
       "2012-01-15               NaN\n",
       "2012-01-22               NaN\n",
       "2012-01-29               NaN\n",
       "2012-02-05               NaN\n",
       "2012-02-12               NaN\n",
       "2012-02-19               NaN\n",
       "2012-02-26               NaN\n",
       "2012-03-04               NaN\n",
       "2012-03-11               NaN\n",
       "2012-03-18               NaN\n",
       "2012-03-25               NaN\n",
       "2012-04-01               NaN\n",
       "2012-04-08               NaN\n",
       "2012-04-15               NaN\n",
       "2012-04-22               NaN\n",
       "2012-04-29               NaN\n",
       "2012-05-06               NaN\n",
       "2012-05-13               NaN\n",
       "2012-05-20               NaN\n",
       "2012-05-27               NaN\n",
       "2012-06-03               NaN\n",
       "2012-06-10               NaN\n",
       "2012-06-17               NaN\n",
       "2012-06-24               NaN\n",
       "2012-07-01               NaN\n",
       "2012-07-08               NaN\n",
       "2012-07-15               NaN\n",
       "2012-07-22               NaN\n",
       "2012-07-29               NaN\n",
       "2012-08-05               NaN\n",
       "2012-08-12               NaN\n",
       "2012-08-19               NaN\n",
       "2012-08-26               NaN\n",
       "2012-09-02               NaN\n",
       "2012-09-09               NaN\n",
       "2012-09-16               NaN\n",
       "2012-09-23               NaN\n",
       "2012-09-30               NaN\n",
       "2012-10-07               NaN\n",
       "2012-10-14               NaN\n",
       "2012-10-21               NaN\n",
       "2012-10-28               NaN\n",
       "2012-11-04               NaN\n",
       "2012-11-11               NaN\n",
       "2012-11-18               NaN\n",
       "2012-11-25               NaN\n",
       "2012-12-02               NaN\n",
       "2012-12-09               NaN\n",
       "2012-12-16               NaN\n",
       "2012-12-23               NaN\n",
       "2013-01-01               NaN\n",
       "2013-01-08               NaN\n",
       "2013-01-15               NaN\n",
       "2013-01-22               NaN\n",
       "2013-01-29               NaN\n",
       "2013-02-05               NaN\n",
       "2013-02-12               NaN\n",
       "2013-02-19               NaN\n",
       "2013-02-26               NaN\n",
       "2013-03-05               NaN\n",
       "2013-03-12               NaN\n",
       "2013-03-19               NaN\n",
       "2013-03-26               NaN\n",
       "2013-04-02               NaN\n",
       "2013-04-09               NaN\n",
       "2013-04-16               NaN\n",
       "2013-04-23               NaN\n",
       "2013-04-30               NaN\n",
       "2013-05-07               NaN\n",
       "2013-05-14               NaN\n",
       "2013-05-21               NaN\n",
       "2013-05-28               NaN\n",
       "2013-06-04               NaN\n",
       "2013-06-11               NaN\n",
       "2013-06-18               NaN\n",
       "2013-06-25               NaN"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_X_train = iq_X_train.reshape(iq_X_train.shape[0], 1, iq_X_train.shape[1])\n",
    "iq_X_test = iq_X_test.reshape(iq_X_test.shape[0], 1, iq_X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-06</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-08</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-08</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-07</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-06</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-08</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-08</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-08</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-06</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-08</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-07</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-25</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2010-07-02, 2010-07-09, 2010-07-16, 2010-07-23, 2010-07-30, 2010-08-06, 2010-08-13, 2010-08-20, 2010-08-27, 2010-09-03, 2010-09-10, 2010-09-17, 2010-09-24, 2010-10-01, 2010-10-08, 2010-10-15, 2010-10-22, 2010-10-29, 2010-11-05, 2010-11-12, 2010-11-19, 2010-11-26, 2010-12-03, 2010-12-10, 2010-12-17, 2010-12-24, 2011-01-01, 2011-01-08, 2011-01-15, 2011-01-22, 2011-01-29, 2011-02-05, 2011-02-12, 2011-02-19, 2011-02-26, 2011-03-05, 2011-03-12, 2011-03-19, 2011-03-26, 2011-04-02, 2011-04-09, 2011-04-16, 2011-04-23, 2011-04-30, 2011-05-07, 2011-05-14, 2011-05-21, 2011-05-28, 2011-06-04, 2011-06-11, 2011-06-18, 2011-06-25, 2011-07-02, 2011-07-09, 2011-07-16, 2011-07-23, 2011-07-30, 2011-08-06, 2011-08-13, 2011-08-20, 2011-08-27, 2011-09-03, 2011-09-10, 2011-09-17, 2011-09-24, 2011-10-01, 2011-10-08, 2011-10-15, 2011-10-22, 2011-10-29, 2011-11-05, 2011-11-12, 2011-11-19, 2011-11-26, 2011-12-03, 2011-12-10, 2011-12-17, 2011-12-24, 2012-01-01, 2012-01-08, 2012-01-15, 2012-01-22, 2012-01-29, 2012-02-05, 2012-02-12, 2012-02-19, 2012-02-26, 2012-03-04, 2012-03-11, 2012-03-18, 2012-03-25, 2012-04-01, 2012-04-08, 2012-04-15, 2012-04-22, 2012-04-29, 2012-05-06, 2012-05-13, 2012-05-20, 2012-05-27, ...]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    if test['city'] == 'sj':\n",
    "        return sj_model.predict(x)\n",
    "    elif test['city'] == 'iq':\n",
    "        return iq_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2010-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2010-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>2010-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2010-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2010-07-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week_start_date\n",
       "260      2010-07-02\n",
       "261      2010-07-09\n",
       "262      2010-07-16\n",
       "263      2010-07-23\n",
       "264      2010-07-30"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 0)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'arrays' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-5a1ed050e9a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miq_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jasonjklim/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonjklim/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1729\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonjklim/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Make arrays at least 2D.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'arrays' referenced before assignment"
     ]
    }
   ],
   "source": [
    "iq_model.predict(iq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
